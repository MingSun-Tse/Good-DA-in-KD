<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Good DA in KD">
  <meta name="keywords" content="Knowledge Distillation, Data Augmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>What Makes a "Good" Data Augmentation in Knowledge Distillation -- A Statistical Perspective</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://github.com/MingSun-Tse/Good-DA-in-KD">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">What Makes a "Good" Data Augmentation in Knowledge Distillation -- A Statistical Perspective</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://huanwang.tech">Huan Wang</a><sup>1,2,*</sup>,</span>
              <span class="author-block">
                <a href="https://suhaslohit.github.io/">Suhas Lohit</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://www.merl.com/people/mjones">Mike Jones</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="http://www1.ece.neu.edu/~yunfu/">Yun Fu</a><sup>1</sup>,
              </span>
            </div>
            <h1 style="font-size:23px;font-weight:bold">NeurIPS 2022</h1>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Northeastern University</span>
              <span class="author-block"><sup>2</sup>MERL</span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">(<sup>*</sup>Work done when Huan was an intern at MERL)</span>
              <span class="author-block">(<sup>&dagger;</sup>Corresponding author: slohit@merl.com)</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2012.02909.pdf"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2012.02909" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>ArXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/MingSun-Tse/Good-DA-in-KD"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div align="center"> <img src="static/images/overview.svg" width="750px"> </div>
        <div class="content has-text-centered">
          We study the question what makes a good data augmentation (DA) in knowledge distillation (KD). A proposition from a statistical perspective is proposed, suggesting that a good DA should minimize the stddev of the teacher's mean probability. Per the proposition, a metric to measure the "goodness" of DA is introduced, which works well empirically.
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            Knowledge distillation (KD) is a general neural network training approach that uses a teacher to guide a student. Existing works mainly study KD from the network output side (e.g., how to design a better KD loss function), while few have attempted to understand it from the input side. Especially, its interplay with data augmentation (DA) has not been well understood. In this paper, we ask: Why do some DA schemes (e.g., CutMix) inherently perform much better than others in KD? What characterizes a “good” DA in KD? Our investigation from a statistical perspective suggests that a good DA scheme should reduce the variance of the teacher’s mean probability, which will eventually lead to a lower generalization error gap for the student. Besides the theoretical understanding, we also propose a new entropy-based data-mixing DA scheme to enhance CutMix. Extensive empirical studies support our claims and demonstrate how we can harvest considerable performance gains simply by using a better DA scheme in distillation.
          </div>
        </div>
      </div>

    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">

          <!-- NeRF results: Blender -->
          <!-- <h2 class="title is-3">1. Visual Comparison on NeRF Synthetic and Realistic Datasets</h2>
          <p>(You may pause the video to review the difference between NeRF and ours)</p>

          <div class="content has-text-centered">
            <video class="video-fluid w-100" controls autoplay loop muted>
              <source src="static/videos/NeRF/blender_chair.mp4" type="video/mp4" />
            </video>
            <p>Scene: Chair (Blender). Left: NeRF (PSNR: 33.90), Right: Ours (PSNR: 36.71)</p>
          </div> -->

        </div>
      </div>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{wang2022what,
          author = {Huan Wang and Suhas Lohit and Michael Jones and Yun Fu},
          title = {What Makes a "Good" Data Augmentation in Knowledge Distillation -- A Statistical Perspective},
          booktitle = {NeurIPS},
          year = {2022}
        }</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div align="center" class="container">
      <div class="columns is-centered">
        <div class="content">
          This website is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
        </div>
      </div>
    </div>
  </footer>

</body>

</html>